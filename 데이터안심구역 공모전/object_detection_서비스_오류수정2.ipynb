{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3156c5-1345-4367-b723-a8f7244f1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00174d06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a71daeb-41db-4132-9757-6a77e0d650d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"abdallahalidev/plantvillage-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531b68c-772f-4800-b37e-1904c03aa67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"abdallahalidev/plantvillage-dataset\")\n",
    "print(\"üìÇ Îç∞Ïù¥ÌÑ∞ÏÖãÏù¥ Ï†ÄÏû•Îêú Í≤ΩÎ°ú:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1fdbb6-6eb5-4ba6-ba88-13eed45b973d",
   "metadata": {},
   "source": [
    "# ---- ÏÖãÌåÖ ÏôÑÎ£å -------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbd14290-011c-480b-9ed6-f33c33a9001f",
   "metadata": {},
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ ÏÑ§Î™Ö\n",
    "\n",
    "1. Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞\n",
    "\n",
    "PlantVillage-Dataset/\n",
    "‚îú‚îÄ‚îÄ color/                ‚Üê Ïª¨Îü¨ Ïù¥ÎØ∏ÏßÄ (Í∞ÄÏû• ÏûêÏ£º ÏÇ¨Ïö©)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Apple___Black_rot/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Apple___Cedar_apple_rust/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Apple___healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Blueberry___healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Cherry_(including_sour)___Powdery_mildew/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Cherry_(including_sour)___healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Corn_(maize)___Common_rust_/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Corn_(maize)___Northern_Leaf_Blight/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Corn_(maize)___healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Grape___Black_rot/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Grape___Esca_(Black_Measles)/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Grape___healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ... (Ï¥ù 38Í∞ú ÌÅ¥ÎûòÏä§)\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ grayscale/            ‚Üê ÌùëÎ∞± Î≤ÑÏ†Ñ (ÏÉâ Ï†ïÎ≥¥ Ï†úÍ±∞)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Apple___Black_rot/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ...\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ segmented/            ‚Üê Î∞∞Í≤Ω Ï†úÍ±∞Îêú Î≤ÑÏ†Ñ\n",
    "    ‚îú‚îÄ‚îÄ Apple___Black_rot/\n",
    "    ‚îú‚îÄ‚îÄ ...\n",
    "\n",
    "2. Îç∞Ïù¥ÌÑ∞ Ï¢ÖÎ•ò \n",
    "38Í∞ú ÌÅ¥ÎûòÏä§, 14Ï¢Ö ÏãùÎ¨º. Í∞Å ÏãùÎ¨ºÎ≥Ñ Ï†ïÏÉÅ + Ïó¨Îü¨ ÏßàÎ≥ë Ìè¥Îçî ÏûàÏùå\n",
    "\n",
    "ex. Apple - Apple___Black_rot/,  Apple___Cedar_apple_rust/,  Apple___healthy/\n",
    "\n",
    "Í∞Å Ìè¥Îçî ÏïàÏóê 256*256 ÌÅ¨Í∏∞Ïùò JPG Ïù¥ÎØ∏ÏßÄ ÏàòÎ∞± ~ ÏàòÏ≤úÏû•Ïù¥ Îì§Ïñ¥ÏûàÏùå "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad114023-c4ca-4c19-81df-623f1cb5c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Îã§Ïö¥Î°úÎìúÎêú Í≤ΩÎ°ú\n",
    "path = Path(r\"/home/min/Îã§Ïö¥Î°úÎìú/archive/plantvillage dataset\")\n",
    "\n",
    "# ÌïòÏúÑ Ìè¥Îçî ÌôïÏù∏\n",
    "print(\"üìÇ ÌïòÏúÑ Ìè¥ÎçîÎì§:\")\n",
    "for item in path.iterdir():\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cf063-11d8-4f9b-95c0-ae8f127162c2",
   "metadata": {},
   "source": [
    "# Ïä§ÎßàÌä∏ÌåúÏóê ÌÇ§Ïö∏ Ïàò ÏûàÎäî Ï¢Ö \n",
    "\n",
    "- Tomato (ÌÜ†ÎßàÌÜ†/Ï≤¥Î¶¨ÌÜ†ÎßàÌÜ†)\n",
    "- Pepper, bell (ÌååÌîÑÎ¶¨Ïπ¥/Í≥†Ï∂îÎ•ò)\n",
    "- Strawberry (Îî∏Í∏∞)\n",
    "\n",
    "Ïù¥ Îç∞Ïù¥ÌÑ∞Îì§ ÏúÑÏ£ºÎ°ú ÌïôÏäµÏãúÏºúÏÑú, Î™©ÌëúÎäî ÎÑ£ÏóàÏùÑ Îïå Î≥ëÎì§ÏóàÎäîÏßÄ, Î≥ëÎì§ÏóàÏúºÎ©¥ Ïñ¥Îäê Î≥ëÏù∏ÏßÄ Î∂ÑÎ•òÌï† Ïàò ÏûàÍ≤å!\n",
    "\n",
    "\n",
    "1. Î™®Îç∏ ÌïôÏäµ Í≥ºÏ†ï : ÏÑ∏ Ï¢ÖÎ™©Ïùò train Îç∞Ïù¥ÌÑ∞Î°ú ÌïôÏäµÏãúÌÇ¥. Ï§ëÏöîÌïú Í≤ÉÏùÄ ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú Ïù¥ÎØ∏ÏßÄÎ•º ÎÑ£ÏóàÏùÑ Îïå Ïù¥Í≤å Ïñ¥Îäê Ï¢ÖÏùò Î¨¥Ïä® ÏßàÎ≥ëÏù∏ÏßÄ Î∂ÑÎ•òÌï† Ïàò ÏûàÍ≤å!\n",
    "2. ÏÑúÎπÑÏä§Ìôî Íµ¨ÏÉÅ : Ïù¥ÎØ∏ÏßÄÎ•º ÎÑ£ÏúºÎ©¥, ÏßÄÍ∏à ÏñòÏùò ÏßàÎ≥ë (ÌïôÏäµÏãúÌÇ® ÎùºÎ≤®)ÏùÑ Ï∂úÎ†•ÌïòÍ≥†, \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e946e3b-4264-42eb-aed0-fe6004614afe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Î™®Îç∏ÎßÅ Ï†Ñ Ï§ÄÎπÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d145c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# color Ìè¥Îçî Í≤ΩÎ°ú\n",
    "color_dir = path / \"color\"\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Ìè¥Îçî Î™©Î°ù\n",
    "classes = [d for d in color_dir.iterdir() if d.is_dir()]\n",
    "print(\"üåø ÌÅ¥ÎûòÏä§ Î™©Î°ù:\", [c.name for c in classes[:5]])  # ÏùºÎ∂ÄÎßå Ï∂úÎ†•\n",
    "\n",
    "# Ï≤´ Î≤àÏß∏ ÌÅ¥ÎûòÏä§Ïùò Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄ Î≥¥Í∏∞\n",
    "sample_img = list(classes[0].glob(\"*.JPG\"))[0] # jpg -> JPG \n",
    "print(\"üñºÔ∏è ÏÉòÌîå Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú:\", sample_img)\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ Î∂àÎü¨Ïò§Í∏∞\n",
    "img = cv2.imread(str(sample_img))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(classes[0].name)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf239b3a-1895-4c1c-a1d4-0b86885b46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val test split\n",
    "\n",
    "from pathlib import Path\n",
    "import random, shutil, yaml, os\n",
    "from PIL import Image\n",
    "\n",
    "# =============================\n",
    "# 0) ÏÑ§Ï†ï\n",
    "# =============================\n",
    "BASE_DIR = Path(\"/home/min/Îã§Ïö¥Î°úÎìú/archive/plantvillage dataset/color\").resolve()  # ÏõêÎ≥∏ Î£®Ìä∏\n",
    "YOLO_OUT = Path.cwd() / \"pv_yolo_tps_multi_splits\"  # Ï∂úÎ†• Î£®Ìä∏(ÏÉàÎ°ú ÏÉùÏÑ±)\n",
    "SEED = 42\n",
    "TARGET_CROPS = {\"Tomato\", \"Pepper,_bell\", \"Strawberry\"}  # ÎåÄÏÉÅ ÏûëÎ¨º\n",
    "\n",
    "# Split ÎπÑÏú® (Ìï©Ïù¥ 1.0Ïù¥ ÎêòÎèÑÎ°ù!)\n",
    "TRAIN_RATIO = 0.80\n",
    "VAL_RATIO   = 0.10\n",
    "TEST_RATIO  = 0.10\n",
    "assert abs((TRAIN_RATIO + VAL_RATIO + TEST_RATIO) - 1.0) < 1e-6, \"Split ÎπÑÏú® Ìï©Í≥ÑÍ∞Ä 1Ïù¥ ÎêòÏñ¥Ïïº Ìï©ÎãàÎã§.\"\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "# =============================\n",
    "# 1) Ï∂úÎ†• Íµ¨Ï°∞ Ï§ÄÎπÑ\n",
    "# =============================\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    (YOLO_OUT / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (YOLO_OUT / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÇ YOLO ÌïôÏäµÏö© Ìè¥Îçî: {YOLO_OUT}\")\n",
    "\n",
    "# =============================\n",
    "# 2) Ïú†Ìã∏\n",
    "# =============================\n",
    "def list_images(root: Path):\n",
    "    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files += list(root.rglob(e))\n",
    "    return files\n",
    "\n",
    "def write_yolo_label(dst_label: Path, cls_id: int):\n",
    "    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤¥Î•º Ìïú ÌÅ¥ÎûòÏä§ Î∞ïÏä§Î°ú ÎùºÎ≤®ÎßÅ (Í≤ÄÏ∂ú Î™®Îç∏ÏùÑ \"Î∂ÑÎ•òÏ≤òÎüº\" ÏÇ¨Ïö©)\n",
    "    dst_label.write_text(f\"{cls_id} 0.5 0.5 1.0 1.0\\n\", encoding=\"utf-8\")\n",
    "\n",
    "def copy_pair(src_img: Path, split: str, cls_id: int):\n",
    "    dst_img = YOLO_OUT / split / \"images\" / src_img.name\n",
    "    dst_lbl = YOLO_OUT / split / \"labels\" / (src_img.stem + \".txt\")\n",
    "    shutil.copy(src_img, dst_img)\n",
    "    write_yolo_label(dst_lbl, cls_id)\n",
    "\n",
    "def parse_crop_and_status(dirname: str):\n",
    "    # 'Tomato___Early_blight' -> ('Tomato','Early_blight')\n",
    "    if \"___\" not in dirname:\n",
    "        return None, None\n",
    "    left, right = dirname.split(\"___\", 1)\n",
    "    return left, right\n",
    "\n",
    "# =============================\n",
    "# 3) ÌÅ¥ÎûòÏä§(Ìè¥Îçî) ÏÑ†Î≥Ñ\n",
    "# =============================\n",
    "if not BASE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°úÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {BASE_DIR}\")\n",
    "\n",
    "class_dirs = [p for p in BASE_DIR.iterdir() if p.is_dir()]\n",
    "picked = []  # (dir_path, class_name)\n",
    "for d in class_dirs:\n",
    "    crop, status = parse_crop_and_status(d.name)\n",
    "    if crop in TARGET_CROPS and status is not None:\n",
    "        # Ìè¥ÎçîÏóê Ïù¥ÎØ∏ÏßÄÍ∞Ä Ïã§Ï†úÎ°ú ÏûàÎäî Í≤ΩÏö∞Îßå ÏÇ¨Ïö©\n",
    "        if any(d.glob(\"*.jpg\")) or any(d.glob(\"*.JPG\")) or any(d.glob(\"*.jpeg\")) or any(d.glob(\"*.png\")):\n",
    "            picked.append((d, d.name))\n",
    "\n",
    "if not picked:\n",
    "    raise RuntimeError(\"ÏÑ†ÌÉù ÏûëÎ¨º(Tomato/Pepper,_bell/Strawberry)ÏóêÏÑú Ïù¥ÎØ∏ÏßÄ Ìè¥ÎçîÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§\n",
    "names = sorted({cls_name for _, cls_name in picked}, key=str.lower)\n",
    "name_to_id = {n: i for i, n in enumerate(names)}\n",
    "print(f\"üéØ ÌÅ¥ÎûòÏä§ Ïàò: {len(names)}\")\n",
    "print(\"ÏòàÏãú ÌÅ¥ÎûòÏä§:\", names[:10], \"...\" if len(names) > 10 else \"\")\n",
    "\n",
    "# =============================\n",
    "# 4) ÌÅ¥ÎûòÏä§Î≥Ñ train/val/test Î∂ÑÌï† & Î≥µÏÇ¨\n",
    "# =============================\n",
    "def split_counts(n, train_ratio, val_ratio, test_ratio):\n",
    "    n_train = int(round(n * train_ratio))\n",
    "    n_val   = int(round(n * val_ratio))\n",
    "    # ÎÇòÎ®∏ÏßÄÎäî testÎ°ú (Ìï©Í≥Ñ Î≥¥Ï†ï)\n",
    "    n_test  = max(0, n - n_train - n_val)\n",
    "    # ÎßåÏïΩ Î∞òÏò¨Î¶º Ïò§Ï∞®Î°ú ÏùåÏàò/Ï¥àÍ≥º ÏÉùÍ∏∞Î©¥ Î≥¥Ï†ï\n",
    "    if n_train + n_val + n_test != n:\n",
    "        diff = n - (n_train + n_val + n_test)\n",
    "        n_test += diff\n",
    "    return n_train, n_val, n_test\n",
    "\n",
    "def process_one_class(img_dir: Path, class_name: str):\n",
    "    cls_id = name_to_id[class_name]\n",
    "    imgs = list_images(img_dir)\n",
    "    if len(imgs) == 0:\n",
    "        print(f\"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå: {img_dir}\")\n",
    "        return\n",
    "\n",
    "    # ÏÜêÏÉÅ Ïù¥ÎØ∏ÏßÄ Ï†úÍ±∞ + ÏÖîÌîå\n",
    "    clean = []\n",
    "    for p in imgs:\n",
    "        try:\n",
    "            Image.open(p).verify()\n",
    "            clean.append(p)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è ÏÜêÏÉÅ/Î∂àÍ∞Ä Ïù¥ÎØ∏ÏßÄ Ï†úÏô∏: {p} ({e})\")\n",
    "    if not clean:\n",
    "        print(f\"‚ö†Ô∏è Ïú†Ìö® Ïù¥ÎØ∏ÏßÄ 0: {img_dir}\")\n",
    "        return\n",
    "\n",
    "    random.shuffle(clean)\n",
    "    n = len(clean)\n",
    "    n_train, n_val, n_test = split_counts(n, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
    "\n",
    "    train_imgs = clean[:n_train]\n",
    "    val_imgs   = clean[n_train:n_train+n_val]\n",
    "    test_imgs  = clean[n_train+n_val:]\n",
    "\n",
    "    for p in train_imgs: copy_pair(p, \"train\", cls_id)\n",
    "    for p in val_imgs:   copy_pair(p, \"val\",   cls_id)\n",
    "    for p in test_imgs:  copy_pair(p, \"test\",  cls_id)\n",
    "\n",
    "    print(f\"  - {class_name}: total={n}, train={len(train_imgs)}, val={len(val_imgs)}, test={len(test_imgs)}\")\n",
    "\n",
    "print(\"üì¶ ÌÅ¥ÎûòÏä§Î≥Ñ Î∂ÑÌï†/ÎùºÎ≤®ÎßÅ ÏãúÏûë...\")\n",
    "for d, cls_name in picked:\n",
    "    process_one_class(d, cls_name)\n",
    "\n",
    "print(\"‚úÖ Î∂ÑÌï† Î∞è ÎùºÎ≤®ÎßÅ ÏôÑÎ£å!\")\n",
    "\n",
    "# =============================\n",
    "# 5) data.yaml ÏÉùÏÑ± (train/val/test Î™®Îëê Í∏∞Î°ù)\n",
    "# =============================\n",
    "yaml_path = YOLO_OUT / \"data.yaml\"\n",
    "data_cfg = {\n",
    "    \"train\": str((YOLO_OUT / \"train\" / \"images\").resolve()),\n",
    "    \"val\":   str((YOLO_OUT / \"val\"   / \"images\").resolve()),\n",
    "    \"test\":  str((YOLO_OUT / \"test\"  / \"images\").resolve()),\n",
    "    \"nc\": len(names),\n",
    "    \"names\": names,  # Ìè¥ÎçîÎ™Ö Í∑∏ÎåÄÎ°ú\n",
    "}\n",
    "yaml_path.write_text(yaml.safe_dump(data_cfg, sort_keys=False, allow_unicode=True), encoding=\"utf-8\")\n",
    "print(f\"‚úÖ data.yaml ÏÉùÏÑ±: {yaml_path.resolve()}\")\n",
    "\n",
    "# =============================\n",
    "# (ÏòµÏÖò) Í∞ÑÎã® Ï†êÍ≤Ä: ÌÅ¥ÎûòÏä§/ÏÉòÌîå Ïàò ÏöîÏïΩ\n",
    "# =============================\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    n_imgs = len(list((YOLO_OUT / split / \"images\").glob(\"*.*\")))\n",
    "    n_lbls = len(list((YOLO_OUT / split / \"labels\").glob(\"*.txt\")))\n",
    "    print(f\"üìä {split}: images={n_imgs}, labels={n_lbls}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac926d-04a4-4298-a518-0e58e3f777b8",
   "metadata": {},
   "source": [
    "# ÌïôÏäµ ÏãúÏûë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865a52b-2154-44f8-be26-e86aa93945e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bbc79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random, shutil, yaml, os, re\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import torch, gc\n",
    "\n",
    "# =============================\n",
    "# 0) ÏÑ§Ï†ï\n",
    "# =============================\n",
    "BASE_DIR = Path(\"/home/min/Îã§Ïö¥Î°úÎìú/archive/plantvillage dataset/color\").resolve()\n",
    "YOLO_OUT = Path.cwd() / \"pv_yolo_tps_multi\"\n",
    "SPLIT_RATIO = 0.85\n",
    "SEED = 42\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ (Î®ºÏ†Ä ÏÑ†Ïñ∏!)\n",
    "MODEL_WEIGHTS = \"yolo11m.pt\"   # VRAM Î∂ÄÏ°±ÌïòÎ©¥ \"yolo11n.pt\"\n",
    "EPOCHS = 5                    # üîß ÏóêÌè≠ 5\n",
    "BATCH = 32\n",
    "IMG_SIZE = 640\n",
    "PATIENCE = 10\n",
    "DEVICE = \"auto\"\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "print(\"üöÄ ÌïôÏäµ ÏãúÏûë (Î©îÎ™®Î¶¨ ÏÑ∏Ïù¥ÌîÑ Î™®Îìú, epochs=10)...\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# VRAM ÏπúÌôî ÏãúÎèÑ ÏàúÏÑú (Ïù¥Ï†ú Ïó¨Í∏∞ÏÑú Ï∞∏Ï°∞ OK)\n",
    "candidate_weights = [MODEL_WEIGHTS, \"yolo11n.pt\"]      # m ‚Üí n\n",
    "candidate_imgsz   = [IMG_SIZE, 512, 448, 384, 320]     # 640 ‚Üí ‚Ä¶\n",
    "candidate_batch   = [-1, 8, 4, 2, 1]                   # -1: Auto-Batch\n",
    "\n",
    "last_save_dir = None\n",
    "\n",
    "\n",
    "# ÌïôÏäµ ÎåÄÏÉÅ ÏûëÎ¨º(Ìè¥ÎçîÏùò Ï¢åÏ∏° ÌÜ†ÌÅ∞; PlantVillage Í∑úÏπôÏÉÅ '___'Î°ú Íµ¨Î∂Ñ)\n",
    "TARGET_CROPS = {\"Tomato\", \"Pepper,_bell\", \"Strawberry\"}  # ÏâºÌëú/Ïñ∏ÎçîÏä§ÏΩîÏñ¥ Ìè¨Ìï® Ï£ºÏùò\n",
    "\n",
    "# =============================\n",
    "# 1) Ï∂úÎ†• Íµ¨Ï°∞ Ï§ÄÎπÑ\n",
    "# =============================\n",
    "for split in [\"train\", \"val\"]:\n",
    "    (YOLO_OUT / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (YOLO_OUT / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÇ YOLO ÌïôÏäµÏö© Ìè¥Îçî: {YOLO_OUT}\")\n",
    "\n",
    "# =============================\n",
    "# 2) Ïú†Ìã∏\n",
    "# =============================\n",
    "def list_images(root: Path):\n",
    "    exts = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"]\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files += list(root.rglob(e))\n",
    "    return files\n",
    "\n",
    "def write_yolo_label(dst_label: Path, cls_id: int):\n",
    "    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤¥Î•º Ìïú ÌÅ¥ÎûòÏä§ Î∞ïÏä§Î°ú\n",
    "    dst_label.write_text(f\"{cls_id} 0.5 0.5 1.0 1.0\\n\", encoding=\"utf-8\")\n",
    "\n",
    "def safe_name(class_name: str, src_img: Path) -> tuple[Path, Path]:\n",
    "    # Ïòà: \"Tomato___Early_blight_0001.jpg\", \"Tomato___Early_blight_0001.txt\"\n",
    "    prefix = re.sub(r\"[^A-Za-z0-9_]+\", \"_\", class_name)  # ÌååÏùºÎ™Ö ÏïàÏ†ÑÌôî\n",
    "    new_stem = f\"{prefix}_{src_img.stem}\"\n",
    "    img_name = new_stem + src_img.suffix\n",
    "    lbl_name = new_stem + \".txt\"\n",
    "    return Path(img_name), Path(lbl_name)\n",
    "\n",
    "def copy_pair(src_img: Path, split: str, cls_id: int, class_name: str):\n",
    "    img_name, lbl_name = safe_name(class_name, src_img)\n",
    "    dst_img = YOLO_OUT / split / \"images\" / img_name\n",
    "    dst_lbl = YOLO_OUT / split / \"labels\" / lbl_name\n",
    "    shutil.copy(src_img, dst_img)\n",
    "    write_yolo_label(dst_lbl, cls_id)\n",
    "\n",
    "\n",
    "def parse_crop_and_status(dirname: str):\n",
    "    \"\"\"\n",
    "    'Tomato___Early_blight' -> ('Tomato', 'Early_blight')\n",
    "    'Pepper,_bell___Bacterial_spot' -> ('Pepper,_bell', 'Bacterial_spot')\n",
    "    'Strawberry___healthy' -> ('Strawberry', 'healthy')\n",
    "    \"\"\"\n",
    "    if \"___\" not in dirname:\n",
    "        return None, None\n",
    "    left, right = dirname.split(\"___\", 1)\n",
    "    return left, right\n",
    "\n",
    "# =============================\n",
    "# 3) ÌÅ¥ÎûòÏä§(Ìè¥Îçî) ÏÑ†Î≥Ñ: Tomato / Pepper,_bell / Strawberry Îßå\n",
    "# =============================\n",
    "if not BASE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°úÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {BASE_DIR}\")\n",
    "\n",
    "class_dirs = [p for p in BASE_DIR.iterdir() if p.is_dir()]\n",
    "picked_dirs = []  # (dir_path, class_name) class_name = ÏõêÎ≥∏ Ìè¥ÎçîÎ™Ö Í∑∏ÎåÄÎ°ú\n",
    "for d in class_dirs:\n",
    "    crop, status = parse_crop_and_status(d.name)\n",
    "    if crop in TARGET_CROPS and status is not None:\n",
    "        # Ïã§Ï†ú Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏûàÏñ¥Ïïº Ïú†Ìö®\n",
    "        if any(d.glob(\"*.jpg\")) or any(d.glob(\"*.JPG\")) or any(d.glob(\"*.jpeg\")) or any(d.glob(\"*.png\")):\n",
    "            picked_dirs.append((d, d.name))\n",
    "\n",
    "if not picked_dirs:\n",
    "    raise RuntimeError(\"ÏÑ†ÌÉùÎêú ÏûëÎ¨º(Tomato/Pepper,_bell/Strawberry)ÏóêÏÑú Ïù¥ÎØ∏ÏßÄ Ìè¥ÎçîÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§.\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Ïù∏Îç±Ïä§ Îß§Ìïë\n",
    "names = sorted(list({cls_name for (_, cls_name) in picked_dirs}), key=str.lower)\n",
    "name_to_id = {n: i for i, n in enumerate(names)}\n",
    "\n",
    "print(f\"üéØ ÏÇ¨Ïö© ÌÅ¥ÎûòÏä§ Ïàò: {len(names)}\")\n",
    "print(\"ÏòàÏãú ÌÅ¥ÎûòÏä§:\", names[:10], \"...\" if len(names) > 10 else \"\")\n",
    "\n",
    "# =============================\n",
    "# 4) Ïù¥ÎØ∏ÏßÄ ÏàòÏßë & Î∂ÑÌï† & ÎùºÎ≤®ÎßÅ\n",
    "# =============================\n",
    "def process_class(img_dir: Path, class_name: str):\n",
    "    cls_id = name_to_id[class_name]\n",
    "    imgs = list_images(img_dir)\n",
    "    if len(imgs) == 0:\n",
    "        print(f\"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ ÏóÜÏùå: {img_dir}\")\n",
    "        return\n",
    "    random.shuffle(imgs)\n",
    "    train_n = int(len(imgs) * SPLIT_RATIO)\n",
    "    train_imgs = imgs[:train_n]\n",
    "    val_imgs = imgs[train_n:]\n",
    "\n",
    "    for p in train_imgs:\n",
    "        try:\n",
    "            Image.open(p).verify()\n",
    "            copy_pair(p, \"train\", cls_id, class_name)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è ÌïôÏäµ Ï†úÏô∏(ÏÜêÏÉÅ): {p} ({e})\")\n",
    "\n",
    "    for p in val_imgs:\n",
    "        try:\n",
    "            Image.open(p).verify()\n",
    "            copy_pair(p, \"val\", cls_id, class_name)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Í≤ÄÏ¶ù Ï†úÏô∏(ÏÜêÏÉÅ): {p} ({e})\")\n",
    "\n",
    "total_counts = {n: 0 for n in names}\n",
    "for d, cls_name in picked_dirs:\n",
    "    cnt = len(list_images(d))\n",
    "    total_counts[cls_name] += cnt\n",
    "    process_class(d, cls_name)\n",
    "\n",
    "print(\"‚úÖ Îç∞Ïù¥ÌÑ∞ Î≥µÏÇ¨/ÎùºÎ≤®ÎßÅ ÏôÑÎ£å!\")\n",
    "print(\"ÌÅ¥ÎûòÏä§Î≥Ñ Ïù¥ÎØ∏ÏßÄ Ïàò(ÏõêÎ≥∏ Í∏∞Ï§Ä, ÏÜêÏÉÅ Ï†úÏô∏ Ï†Ñ):\")\n",
    "for n in names:\n",
    "    print(f\"  - {n}: ~{total_counts[n]}\")\n",
    "\n",
    "# =============================\n",
    "# 5) data.yaml ÏÉùÏÑ±\n",
    "# =============================\n",
    "yaml_path = YOLO_OUT / \"data.yaml\"\n",
    "data_cfg = {\n",
    "    \"train\": str((YOLO_OUT / \"train\" / \"images\").resolve()),\n",
    "    \"val\": str((YOLO_OUT / \"val\" / \"images\").resolve()),\n",
    "    \"nc\": len(names),\n",
    "    \"names\": names  # Í∑∏ÎåÄÎ°ú Ï†ÄÏû•(ÏâºÌëú/Í¥ÑÌò∏/Ïä§ÌéòÏù¥Ïä§ Ìè¨Ìï® Í∞ÄÎä•)\n",
    "}\n",
    "yaml_path.write_text(yaml.safe_dump(data_cfg, sort_keys=False, allow_unicode=True), encoding=\"utf-8\")\n",
    "print(f\"‚úÖ data.yaml ÏÉùÏÑ±: {yaml_path}\")\n",
    "\n",
    "# =============================\n",
    "# 6) YOLOv11 ÌïôÏäµ (Î©îÎ™®Î¶¨-ÏÑ∏Ïù¥ÌîÑ, epochs=10)\n",
    "# =============================\n",
    "\n",
    "def try_once(weights, imgsz, batch):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"\\n‚ñ∂ ÏãúÎèÑ: weights={weights}, imgsz={imgsz}, batch={batch}\")\n",
    "\n",
    "    model = YOLO(weights)\n",
    "    res = model.train(\n",
    "        data=str(yaml_path),            # data.yamlÏùò train/val ÏÇ¨Ïö©(ÌïôÏäµÏùÄ trainÎßå, valÏùÄ Í≤ÄÏ¶ù/ÏÑ†ÌÉù)\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,                    # Auto-BatchÎ∂ÄÌÑ∞ ÏãúÎèÑ\n",
    "        name=\"smartfarm_tps_multi\",\n",
    "        seed=SEED,\n",
    "        device=\"0\" if DEVICE == \"auto\" else DEVICE,\n",
    "\n",
    "        # üîΩ Î©îÎ™®Î¶¨ Ï†àÏïΩ ÏòµÏÖò\n",
    "        workers=0,                      # dataloader Î©îÎ™®Î¶¨ Ï†àÏïΩ\n",
    "        amp=True,                       # FP16 ÌòºÌï©Ï†ïÎ∞Ä\n",
    "        cache=False,                    # Ïù¥ÎØ∏ÏßÄ Ï∫êÏãú ÎπÑÌôúÏÑ±Ìôî\n",
    "        plots=False,                    # ÌîåÎ°Ø ÏÉùÏÑ± ÎÅî\n",
    "        deterministic=False,            # ÏÑ±Îä• Ïö∞ÏÑ†\n",
    "        close_mosaic=10,                # ÌõÑÎ∞òÎ∂Ä Î™®ÏûêÏù¥ÌÅ¨ ÎÅÑÍ∏∞(ÏïàÏ†ï)\n",
    "        patience=PATIENCE,              # early stopping\n",
    "        cos_lr=True,\n",
    "        verbose=True,\n",
    "        resume=False,\n",
    "    )\n",
    "\n",
    "    # save_dir ÏñªÍ∏∞ (Î≤ÑÏ†Ñ Ìò∏Ìôò)\n",
    "    save_dir = None\n",
    "    try:\n",
    "        save_dir = Path(res.save_dir)\n",
    "    except Exception:\n",
    "        try:\n",
    "            save_dir = Path(model.trainer.save_dir)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return save_dir\n",
    "\n",
    "trained = False\n",
    "for w in candidate_weights:\n",
    "    for s in candidate_imgsz:\n",
    "        for b in candidate_batch:\n",
    "            try:\n",
    "                last_save_dir = try_once(w, s, b)\n",
    "                if last_save_dir is None:\n",
    "                    # Î∞±ÏóÖ: runs/detect ÌïòÏúÑÏóêÏÑú Í∞ÄÏû• ÏµúÍ∑º smartfarm_tps_multi ÌÉêÏÉâ\n",
    "                    cand = sorted(Path(\"runs/detect\").glob(\"smartfarm_tps_multi*\"),\n",
    "                                  key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "                    if cand:\n",
    "                        last_save_dir = cand[0]\n",
    "                trained = True\n",
    "                print(\"‚úÖ ÌïôÏäµ ÏÑ±Í≥µ!\")\n",
    "                break\n",
    "            except RuntimeError as e:\n",
    "                msg = str(e)\n",
    "                if (\"CUDA out of memory\" in msg) or (\"cuDNN\" in msg) or (\"CUBLAS\" in msg):\n",
    "                    print(\"‚ö†Ô∏è OOM/ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏóêÎü¨ ‚Üí ÌååÎùºÎØ∏ÌÑ∞ ÎÇÆÏ∂∞ Ïû¨ÏãúÎèÑ\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise\n",
    "        if trained: break\n",
    "    if trained: break\n",
    "\n",
    "if not trained:\n",
    "    raise RuntimeError(\"Î™®Îì† Ï°∞Ìï©ÏóêÏÑú ÌïôÏäµ Ïã§Ìå®: VRAM/ÌôòÍ≤Ω/Îç∞Ïù¥ÌÑ∞Î•º ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")\n",
    "\n",
    "# =============================\n",
    "# 7) best.pt Ï∞æÍ∏∞ & val ÏÑ±Îä• ÌèâÍ∞Ä(Î©îÎ™®Î¶¨ Ï†àÏïΩ)\n",
    "# =============================\n",
    "best_pt = None\n",
    "if last_save_dir:\n",
    "    cand = (last_save_dir / \"weights\" / \"best.pt\")\n",
    "    if cand.exists():\n",
    "        best_pt = cand\n",
    "\n",
    "if best_pt is None:\n",
    "    all_best = sorted(\n",
    "        Path(\"runs/detect\").glob(\"smartfarm_tps_multi*/weights/best.pt\"),\n",
    "        key=lambda p: p.stat().st_mtime, reverse=True\n",
    "    )\n",
    "    best_pt = all_best[0] if all_best else None\n",
    "\n",
    "if best_pt is None:\n",
    "    raise FileNotFoundError(\"best.ptÎ•º Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. ÌïôÏäµ Î°úÍ∑∏Î•º ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")\n",
    "\n",
    "print(f\"üèÜ best.pt: {best_pt.resolve()}\")\n",
    "\n",
    "print(\"üß™ val ÏÑ±Îä• ÌèâÍ∞Ä ÏãúÏûë (Î©îÎ™®Î¶¨ ÏÑ∏Ïù¥ÌîÑ)...\")\n",
    "eval_model = YOLO(str(best_pt))\n",
    "val_results = eval_model.val(\n",
    "    data=str(yaml_path),\n",
    "    split=\"val\",\n",
    "    imgsz=min(IMG_SIZE, 512),           # ÌèâÍ∞Ä Ìï¥ÏÉÅÎèÑÎèÑ ÏïΩÍ∞Ñ Î≥¥ÏàòÏ†ÅÏúºÎ°ú\n",
    "    batch=max(1, BATCH//2),             # Î∞∞Ïπò Ï∂ïÏÜå\n",
    "    device=\"0\" if DEVICE == \"auto\" else DEVICE,\n",
    "    workers=0,\n",
    "    plots=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    mp     = val_results.results_dict.get(\"metrics/precision(B)\", None)\n",
    "    mr     = val_results.results_dict.get(\"metrics/recall(B)\", None)\n",
    "    map50  = val_results.results_dict.get(\"metrics/mAP50(B)\", None)\n",
    "    map5095= val_results.results_dict.get(\"metrics/mAP50-95(B)\", None)\n",
    "    print(f\"üìä Precision: {mp:.4f} ¬∑ Recall: {mr:.4f} ¬∑ mAP@50: {map50:.4f} ¬∑ mAP@50-95: {map5095:.4f}\")\n",
    "except Exception:\n",
    "    print(\"üìä ÌèâÍ∞Ä Í≤∞Í≥º:\", getattr(val_results, \"results_dict\", val_results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65797eb-00ba-485a-a3de-b395382fb566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import glob\n",
    "\n",
    "pred_dir = \"runs/detect/predict\"\n",
    "for img_path in glob.glob(f\"{pred_dir}/*.jpg\")[:5]:  # ÏùºÎ∂ÄÎßå\n",
    "    print(img_path)\n",
    "    display(Image.open(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff313121-b1ee-49c7-a647-cc65307fcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()\n",
    "print(metrics.box.map)     # mAP@0.5:0.95\n",
    "print(metrics.box.map50)   # mAP@0.5\n",
    "print(metrics.box.map75)   # mAP@0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14971013-6fe6-42b2-b7bb-ed40960eb99d",
   "metadata": {},
   "source": [
    "# ÏÑúÎπÑÏä§ Ï¢Ä Îçî Ïã¨ÌôîÎ≤ÑÏ†Ñ\n",
    "\n",
    "- Ïö∞Î¶¨Í∞Ä ÏõêÌïòÎäî Í∏∞Îä•Îì§ Îì§Ïñ¥Í∞ÄÍ≤å ÏôÑÏ†ÑÏ≤¥Î°ú\n",
    "\n",
    "- best.pt, json ÌååÏùº Í≤ΩÎ°ú ÌôòÍ≤ΩÏóê ÎßûÍ≤å ÏàòÏ†ï ÌïÑÏöî\n",
    "\n",
    "- Ïó¨Í∏∞ÏÑúÎ∂ÄÌÑ∞ ÎèåÎ¶¨Î©¥ ÏÑúÎπÑÏä§ Íµ¨ÌòÑÎê® !"
   ]
  },
  {
   "cell_type": "raw",
   "id": "049551dc-46a2-47c9-9c33-f549e9cff8e5",
   "metadata": {},
   "source": [
    "User: \"Ïù¥ Ïûé ÏÇ¨ÏßÑÏù¥ Î≥ëÎì† Í±¥ÏßÄ ÌôïÏù∏Ìï¥Ï§ò\"\n",
    "‚Üì\n",
    "LLM (ChatGPT, GPT-4, Claude Îì±)\n",
    "‚Üì\n",
    "AgentÍ∞Ä YOLO Ìà¥(diagnose_leaf)ÏùÑ ÏßÅÏ†ë Ìò∏Ï∂ú\n",
    "‚Üì\n",
    "Í≤∞Í≥º Ìï¥ÏÑù + ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏûêÏó∞Ïñ¥Î°ú ÏùëÎãµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c76b3c-0ab5-46bc-8dba-8e3ae02cf2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph>=0.2.40\n",
      "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langchain-openai>=0.2.0\n",
      "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langchain-community>=0.2.0\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph>=0.2.40)\n",
      "  Downloading langchain_core-1.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph>=0.2.40)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph>=0.2.40)\n",
      "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph>=0.2.40)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.7.4 (from langgraph>=0.2.40)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph>=0.2.40)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph>=0.2.40)\n",
      "  Downloading ormsgpack-1.12.0-cp310-cp310-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40)\n",
      "  Downloading orjson-3.11.4-cp310-cp310-win_amd64.whl.metadata (42 kB)\n",
      "Collecting openai<3.0.0,>=1.109.1 (from langchain-openai>=0.2.0)\n",
      "  Downloading openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai>=0.2.0)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Downloading langsmith-0.4.41-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core>=0.1->langgraph>=0.2.40) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core>=0.1->langgraph>=0.2.40) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core>=0.1->langgraph>=0.2.40) (4.14.1)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.2.40) (2.32.3)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<3.0.0,>=1.109.1->langchain-openai>=0.2.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.109.1->langchain-openai>=0.2.0)\n",
      "  Downloading jiter-0.11.1-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<3.0.0,>=1.109.1->langchain-openai>=0.2.0)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai>=0.2.0) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\jeongmin\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.2.40) (1.3.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langgraph>=0.2.40)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.7.4->langgraph>=0.2.40)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.7.4->langgraph>=0.2.40)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai>=0.2.0) (2025.7.34)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community>=0.2.0)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community>=0.2.0)\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.2.40)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community>=0.2.0)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community>=0.2.0)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community>=0.2.0)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community>=0.2.0)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-community>=0.2.0) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.2.0)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.2.0)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community>=0.2.0)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community>=0.2.0)\n",
      "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community>=0.2.0)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.2.40) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph>=0.2.40) (2.3.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community>=0.2.0)\n",
      "  Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community>=0.2.0)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai>=0.2.0) (0.4.6)\n",
      "Downloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
      "Downloading langchain_core-1.0.3-py3-none-any.whl (469 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.4.41-py3-none-any.whl (399 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.9 MB/s  0:00:00\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.11.1-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.8/2.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 9.4 MB/s  0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 879.4/879.4 kB 10.0 MB/s  0:00:00\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 9.1 MB/s  0:00:00\n",
      "Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl (455 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 7.1 MB/s  0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.1/2.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 8.5 MB/s  0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading orjson-3.11.4-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.12.0-cp310-cp310-win_amd64.whl (112 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp310-cp310-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, typing-inspection, tenacity, sniffio, requests, python-dotenv, pydantic-core, propcache, ormsgpack, orjson, mypy-extensions, multidict, marshmallow, jsonpointer, jiter, httpx-sse, h11, greenlet, frozenlist, distro, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, aiosignal, pydantic-settings, httpx, dataclasses-json, aiohttp, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph-prebuilt, langchain-classic, langgraph, langchain-community\n",
      "\n",
      "    ---------------------------------------  1/49 [xxhash]\n",
      "   -- -------------------------------------  3/49 [tenacity]\n",
      "   --- ------------------------------------  4/49 [sniffio]\n",
      "  Attempting uninstall: requests\n",
      "   --- ------------------------------------  4/49 [sniffio]\n",
      "    Found existing installation: requests 2.32.3\n",
      "   --- ------------------------------------  4/49 [sniffio]\n",
      "    Uninstalling requests-2.32.3:\n",
      "   --- ------------------------------------  4/49 [sniffio]\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "   --- ------------------------------------  4/49 [sniffio]\n",
      "   ---- -----------------------------------  5/49 [requests]\n",
      "   ---- -----------------------------------  5/49 [requests]\n",
      "   ---- -----------------------------------  6/49 [python-dotenv]\n",
      "   ----- ----------------------------------  7/49 [pydantic-core]\n",
      "   ------ ---------------------------------  8/49 [propcache]\n",
      "   -------- ------------------------------- 10/49 [orjson]\n",
      "   --------- ------------------------------ 12/49 [multidict]\n",
      "   ---------- ----------------------------- 13/49 [marshmallow]\n",
      "   ------------- -------------------------- 16/49 [httpx-sse]\n",
      "   ------------- -------------------------- 17/49 [h11]\n",
      "   -------------- ------------------------- 18/49 [greenlet]\n",
      "   -------------- ------------------------- 18/49 [greenlet]\n",
      "   -------------- ------------------------- 18/49 [greenlet]\n",
      "   ---------------- ----------------------- 20/49 [distro]\n",
      "   ------------------ --------------------- 23/49 [aiohappyeyeballs]\n",
      "   ------------------- -------------------- 24/49 [yarl]\n",
      "   --------------------- ------------------ 26/49 [tiktoken]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 27/49 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 28/49 [requests-toolbelt]\n",
      "   ---------------------- ----------------- 28/49 [requests-toolbelt]\n",
      "   ---------------------- ----------------- 28/49 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ----------------------- ---------------- 29/49 [pydantic]\n",
      "   ------------------------ --------------- 30/49 [jsonpatch]\n",
      "   ------------------------- -------------- 31/49 [httpcore]\n",
      "   ------------------------- -------------- 31/49 [httpcore]\n",
      "   ------------------------- -------------- 31/49 [httpcore]\n",
      "   -------------------------- ------------- 32/49 [anyio]\n",
      "   -------------------------- ------------- 32/49 [anyio]\n",
      "   -------------------------- ------------- 32/49 [anyio]\n",
      "   -------------------------- ------------- 32/49 [anyio]\n",
      "   --------------------------- ------------ 34/49 [pydantic-settings]\n",
      "   --------------------------- ------------ 34/49 [pydantic-settings]\n",
      "   ---------------------------- ----------- 35/49 [httpx]\n",
      "   ---------------------------- ----------- 35/49 [httpx]\n",
      "   ---------------------------- ----------- 35/49 [httpx]\n",
      "   ----------------------------- ---------- 36/49 [dataclasses-json]\n",
      "   ------------------------------ --------- 37/49 [aiohttp]\n",
      "   ------------------------------ --------- 37/49 [aiohttp]\n",
      "   ------------------------------ --------- 37/49 [aiohttp]\n",
      "   ------------------------------ --------- 37/49 [aiohttp]\n",
      "   ------------------------------ --------- 37/49 [aiohttp]\n",
      "   ------------------------------ --------- 37/49 [aiohttp]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 38/49 [openai]\n",
      "   ------------------------------- -------- 39/49 [langsmith]\n",
      "   ------------------------------- -------- 39/49 [langsmith]\n",
      "   ------------------------------- -------- 39/49 [langsmith]\n",
      "   ------------------------------- -------- 39/49 [langsmith]\n",
      "   ------------------------------- -------- 39/49 [langsmith]\n",
      "   ------------------------------- -------- 39/49 [langsmith]\n",
      "   -------------------------------- ------- 40/49 [langgraph-sdk]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   --------------------------------- ------ 41/49 [langchain-core]\n",
      "   ---------------------------------- ----- 42/49 [langgraph-checkpoint]\n",
      "   ---------------------------------- ----- 42/49 [langgraph-checkpoint]\n",
      "   ----------------------------------- ---- 43/49 [langchain-text-splitters]\n",
      "   ----------------------------------- ---- 44/49 [langchain-openai]\n",
      "   ----------------------------------- ---- 44/49 [langchain-openai]\n",
      "   ------------------------------------ --- 45/49 [langgraph-prebuilt]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   ------------------------------------- -- 46/49 [langchain-classic]\n",
      "   -------------------------------------- - 47/49 [langgraph]\n",
      "   -------------------------------------- - 47/49 [langgraph]\n",
      "   -------------------------------------- - 47/49 [langgraph]\n",
      "   -------------------------------------- - 47/49 [langgraph]\n",
      "   -------------------------------------- - 47/49 [langgraph]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------  48/49 [langchain-community]\n",
      "   ---------------------------------------- 49/49 [langchain-community]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.11.0 async-timeout-4.0.3 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.8.0 greenlet-3.2.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 jiter-0.11.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.3 langchain-openai-1.0.2 langchain-text-splitters-1.0.0 langgraph-1.0.2 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 langsmith-0.4.41 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 openai-2.7.1 orjson-3.11.4 ormsgpack-1.12.0 propcache-0.4.1 pydantic-2.12.4 pydantic-core-2.41.5 pydantic-settings-2.11.0 python-dotenv-1.2.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.12.0 typing-inspect-0.9.0 typing-inspection-0.4.2 xxhash-3.6.0 yarl-1.22.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"langgraph>=0.2.40\" \"langchain-openai>=0.2.0\" \"langchain-community>=0.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3825ffd-8f8d-4846-8f67-bd045400d49d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.3.223)\n",
      "Requirement already satisfied: pillow in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.1.0)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.2.6)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (6.32.1)\n",
      "Collecting pyarrow<22,>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from streamlit) (4.14.1)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\jeongmin\\appdata\\roaming\\python\\python310\\site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.10.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.9.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.35.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.28.0-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: polars-runtime-32==1.35.1 in c:\\users\\jeongmin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from polars->ultralytics) (1.35.1)\n",
      "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.2 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.2 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.9/10.2 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 8.5 MB/s  0:00:01\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 10.2 MB/s  0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.6/26.2 MB 11.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 5.0/26.2 MB 11.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.6/26.2 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.7/26.2 MB 11.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.3/26.2 MB 11.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.7/26.2 MB 11.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 17.0/26.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.7/26.2 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.0/26.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.4/26.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 10.3 MB/s  0:00:02\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.6/6.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.0/6.9 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 10.4 MB/s  0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading narwhals-2.10.2-py3-none-any.whl (419 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.28.0-cp310-cp310-win_amd64.whl (223 kB)\n",
      "Installing collected packages: watchdog, toml, smmap, rpds-py, pyarrow, narwhals, cachetools, blinker, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   ----------------------------------------  0/16 [watchdog]\n",
      "   ----------------------------------------  0/16 [watchdog]\n",
      "   -- -------------------------------------  1/16 [toml]\n",
      "   ------- --------------------------------  3/16 [rpds-py]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ---------- -----------------------------  4/16 [pyarrow]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   ------------ ---------------------------  5/16 [narwhals]\n",
      "   --------------- ------------------------  6/16 [cachetools]\n",
      "   -------------------- -------------------  8/16 [referencing]\n",
      "   ---------------------- -----------------  9/16 [pydeck]\n",
      "   ---------------------- -----------------  9/16 [pydeck]\n",
      "   ---------------------- -----------------  9/16 [pydeck]\n",
      "   ---------------------- -----------------  9/16 [pydeck]\n",
      "   ------------------------- -------------- 10/16 [gitdb]\n",
      "   ------------------------- -------------- 10/16 [gitdb]\n",
      "   --------------------------- ------------ 11/16 [jsonschema-specifications]\n",
      "   ------------------------------ --------- 12/16 [gitpython]\n",
      "   ------------------------------ --------- 12/16 [gitpython]\n",
      "   ------------------------------ --------- 12/16 [gitpython]\n",
      "   -------------------------------- ------- 13/16 [jsonschema]\n",
      "   -------------------------------- ------- 13/16 [jsonschema]\n",
      "   -------------------------------- ------- 13/16 [jsonschema]\n",
      "   -------------------------------- ------- 13/16 [jsonschema]\n",
      "   ----------------------------------- ---- 14/16 [altair]\n",
      "   ----------------------------------- ---- 14/16 [altair]\n",
      "   ----------------------------------- ---- 14/16 [altair]\n",
      "   ----------------------------------- ---- 14/16 [altair]\n",
      "   ----------------------------------- ---- 14/16 [altair]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ------------------------------------- -- 15/16 [streamlit]\n",
      "   ---------------------------------------- 16/16 [streamlit]\n",
      "\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 cachetools-6.2.1 gitdb-4.0.12 gitpython-3.1.45 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 narwhals-2.10.2 pyarrow-21.0.0 pydeck-0.9.1 referencing-0.37.0 rpds-py-0.28.0 smmap-5.0.2 streamlit-1.51.0 toml-0.10.2 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "# ÏÑúÎπÑÏä§ base siteÏù∏ streamlit ÏÑ§Ïπò ÌïÑÏöî \n",
    "!pip install streamlit ultralytics pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d477886-0f73-486a-9639-df62ce7fe58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji==1.7.0Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171074 sha256=ecf4dc5a2b636b2657120853e9f5d564e0d4033ce7d3bbc83011f20263875001\n",
      "  Stored in directory: c:\\users\\jeongmin\\appdata\\local\\pip\\cache\\wheels\\31\\8a\\8c\\315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'emoji' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'emoji'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install emoji==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46f0a3b-4c2e-44da-9333-de5e0efaf630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# üí° Ïó¨Í∏∞Ïóê Î≥∏Ïù∏ OpenAI API ÌÇ§ ÏûÖÎ†•\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cedd8bc-80c3-4eb9-9e7c-734cbb371560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "best_pt = Path(r\"C:/Users/jeongmin/Downloads/best.pt\").resolve() # Í≤ΩÎ°ú ÌôòÍ≤ΩÏóê ÎßûÍ≤å Î≥ÄÍ≤Ω \n",
    "best_pt.exists()  # ‚Üí True Ïó¨Ïïº Ìï®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29dcb3ad-ecca-41ca-94b7-a22b0caa1d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting plant_pet_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile plant_pet_app.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "import streamlit as st\n",
    "from PIL import Image, ImageDraw\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# (ÏÑ†ÌÉù) LLM Î≥¥Í∞ï Î™®ÎìúÏö© - ÏÑ§ÏπòÎêòÏñ¥ ÏûàÎã§Î©¥ ÏÇ¨Ïö©\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "except Exception:\n",
    "    ChatOpenAI = None\n",
    "\n",
    "# =========================\n",
    "# 0) ÏÑ§Ï†ï\n",
    "# =========================\n",
    "# Îã§Ï§ëÎ∂ÑÎ•òÎ°ú ÌïôÏäµÌïú Í∞ÄÏ§ëÏπòÎ•º Í∏∞Î≥∏Í∞íÏúºÎ°ú Í∂åÏû• (ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú ÏûêÏú† Î≥ÄÍ≤Ω)\n",
    "DEFAULT_WEIGHTS = Path(r\"C:/Users/jeongmin/Downloads/best.pt\").resolve() # ÎÇ¥Í∞Ä Î≥¥ÎÇ¥Ï§ÄÍ±∏Î°ú Í≤ΩÎ°ú Î≥ÄÍ≤Ω\n",
    "STATE_FILE = Path(\"./plant_state.json\").resolve() # ÎÇ¥Í∞Ä Î≥¥ÎÇ¥Ï§ÄÍ±∏Î°ú Í≤ΩÎ°ú Î≥ÄÍ≤Ω\n",
    "CONF_THRES = 0.35  # ÏïΩÍ∞Ñ ÎÇÆÏ∂∞ recall ÌôïÎ≥¥\n",
    "\n",
    "# =========================\n",
    "# 1) ÏÉÅÌÉú Ï†ÄÏû•/Î∂àÎü¨Ïò§Í∏∞\n",
    "# =========================\n",
    "DEFAULT_STATE = {\n",
    "    \"name\": \"ÎÇòÏùò Î∞òÎ†§ÏãùÎ¨º\",\n",
    "    \"moisture\": 70,\n",
    "    \"humidity\": 60,\n",
    "    \"temperature\": 24,\n",
    "    \"nutrients\": 60,\n",
    "    \"happiness\": 70,\n",
    "    \"last_update\": time.time(),\n",
    "    \"last_label\": None,   # ex) Tomato___Early_blight\n",
    "    \"last_conf\": None,\n",
    "    \"last_crop\": None,\n",
    "    \"last_disease\": None,\n",
    "}\n",
    "\n",
    "def clamp(val, lo, hi): return max(lo, min(hi, val))\n",
    "\n",
    "def load_state() -> Dict:\n",
    "    if STATE_FILE.exists():\n",
    "        try:\n",
    "            return json.loads(STATE_FILE.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return DEFAULT_STATE.copy()\n",
    "\n",
    "def save_state(state: Dict):\n",
    "    STATE_FILE.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def decay_state(state: Dict):\n",
    "    now = time.time()\n",
    "    dt = now - state.get(\"last_update\", now)\n",
    "    if dt <= 0:\n",
    "        return state\n",
    "    per_hour = {\"moisture\": 2.0, \"humidity\": 1.2, \"nutrients\": 0.6, \"happiness\": 0.8}\n",
    "    scale = dt / 3600.0\n",
    "    for k, v in per_hour.items():\n",
    "        state[k] = clamp(state[k] - v * scale, 0, 100)\n",
    "    drift = 0.4 * scale\n",
    "    state[\"temperature\"] = (max(24, state[\"temperature\"] - drift)\n",
    "                            if state[\"temperature\"] > 24\n",
    "                            else min(24, state[\"temperature\"] + drift))\n",
    "    state[\"last_update\"] = now\n",
    "    return state\n",
    "\n",
    "# =========================\n",
    "# 2) YOLO Î°úÎìú & Îã§Ï§ëÌÅ¥ÎûòÏä§ Ï∂îÎ°†\n",
    "# =========================\n",
    "@st.cache_resource(show_spinner=True)\n",
    "def load_yolo(weights_path: Path) -> YOLO:\n",
    "    if not weights_path.exists():\n",
    "        st.error(f\"YOLO Í∞ÄÏ§ëÏπòÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {weights_path}\")\n",
    "        st.stop()\n",
    "    return YOLO(str(weights_path))\n",
    "\n",
    "def parse_label(full_label: str) -> Tuple[str, str]:\n",
    "    if \"___\" in full_label:\n",
    "        crop, disease = full_label.split(\"___\", 1)\n",
    "        return crop, disease\n",
    "    # ÎπÑÏ†ïÏÉÅ ÎùºÎ≤® ÎåÄÎπÑ\n",
    "    return full_label, \"unknown\"\n",
    "\n",
    "def yolo_predict_multiclass(model: YOLO, image_path: Path) -> Tuple[str, float, str, str]:\n",
    "    \"\"\"ÎùºÎ≤®/Ïã†Î¢∞ÎèÑ/ÏûëÎ¨º/ÏßàÎ≥ë Î∞òÌôò: (label, conf, crop, disease)\"\"\"\n",
    "    res = model.predict(source=str(image_path), conf=CONF_THRES, save=False, verbose=False)\n",
    "    if not res:\n",
    "        return (\"unknown\", 0.0, \"unknown\", \"unknown\")\n",
    "    r0 = res[0]\n",
    "    boxes = getattr(r0, \"boxes\", None)\n",
    "    if boxes is None or len(boxes) == 0:\n",
    "        return (\"unknown\", 0.0, \"unknown\", \"unknown\")\n",
    "    # ÏµúÏÉÅÏúÑ Î∞ïÏä§ 1Í∞ú\n",
    "    idx = int(boxes.conf.argmax().item())\n",
    "    cls_id = int(boxes.cls[idx].item())\n",
    "    conf = float(boxes.conf[idx].item())\n",
    "    label = r0.names.get(cls_id, str(cls_id))\n",
    "    crop, disease = parse_label(label)\n",
    "    return (label, conf, crop, disease)\n",
    "\n",
    "# =========================\n",
    "# 3) Ï∫êÎ¶≠ÌÑ∞ ÏïÑÎ∞îÌÉÄ (Ïßë ÏïÑÏù¥ÏΩò Ïä§ÌÉÄÏùº)\n",
    "# =========================\n",
    "\n",
    "\n",
    "def _rect(draw, box, fill=None, outline=None, width=1):\n",
    "    \"\"\"\n",
    "    ÏßÅÍ∞Å ÏÇ¨Í∞ÅÌòï Ïú†Ìã∏ (ÎùºÏö¥Îìú ÏóÜÏùå)\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = box\n",
    "    draw.rectangle([x0, y0, x1, y1], fill=fill, outline=outline, width=width)\n",
    "\n",
    "\n",
    "def _draw_house_outline(d, W, H):\n",
    "    # Ïßë Ïô∏Í≥ΩÏÑ† (Ï≤®Î∂Ä Ïù¥ÎØ∏ÏßÄ ÎäêÎÇå)\n",
    "    pad = 28\n",
    "    roof_h = int(H*0.22)\n",
    "    lw = 10\n",
    "    color = (133, 170, 196)  # Ïó∞Ìïú ÌååÎûë\n",
    "    # Î™∏ÌÜµ\n",
    "    _rect(d, (pad, pad+roof_h, W-pad, H-pad), outline=color, width=lw)\n",
    "    # ÏßÄÎ∂ï(Ïó≠ VÏûê)\n",
    "    top_x, top_y = W//2, pad\n",
    "    left_x, left_y = pad, pad+roof_h\n",
    "    right_x, right_y = W-pad, pad+roof_h\n",
    "    d.line([left_x, left_y, top_x, top_y, right_x, right_y], fill=color, width=lw, joint=\"curve\")\n",
    "\n",
    "\n",
    "def draw_plant_avatar(state: Dict, full_label: str) -> Image.Image:\n",
    "    \"\"\"\n",
    "    2x2 ÌîΩÏÖÄ Ï∫êÎ¶≠ÌÑ∞ ÏãúÌä∏ÏóêÏÑú ÏÉÅÌÉúÎ≥ÑÎ°ú Ïò¨Î∞îÎ•∏ Ï∫êÎ¶≠ÌÑ∞Î•º ÏûòÎùºÏÑú ÌëúÏãú.\n",
    "    (Ï¢åÏÉÅÎã®=ÌñâÎ≥µ, Ïö∞ÏÉÅÎã®=Ïä¨Ìîî, Ï¢åÌïòÎã®=ÏãúÎì¶, Ïö∞ÌïòÎã®=ÌôúÏßù)\n",
    "    \"\"\"\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    from pathlib import Path\n",
    "\n",
    "    try:\n",
    "        from pilmoji import Pilmoji\n",
    "        HAVE_PILMOJI = True\n",
    "    except Exception:\n",
    "        HAVE_PILMOJI = False\n",
    "\n",
    "    # ‚úÖ 1. Ï∫êÎ¶≠ÌÑ∞ ÏãúÌä∏ Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú\n",
    "    sheet_path = Path(r\"C:/Users/jeongmin/Downloads/A_pixel_art_digital_illustration_features_four_pot.png\")\n",
    "\n",
    "    if not sheet_path.exists():\n",
    "        st.error(\"‚ö†Ô∏è Ï∫êÎ¶≠ÌÑ∞ ÏãúÌä∏ Ïù¥ÎØ∏ÏßÄÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
    "        st.stop()\n",
    "\n",
    "    sheet = Image.open(sheet_path).convert(\"RGBA\")\n",
    "    W, H = sheet.size\n",
    "    cell_w, cell_h = W // 2, H // 2  # 2x2 Î∂ÑÌï†\n",
    "\n",
    "    # ‚úÖ 2. ÏßàÎ≥ëÎ™Ö Î∂ÑÏÑù ‚Üí Ï∫êÎ¶≠ÌÑ∞ ÏúÑÏπò Í≤∞Ï†ï\n",
    "    disease = full_label.split(\"___\", 1)[1] if \"___\" in full_label else full_label\n",
    "    label_lower = disease.lower() if isinstance(disease, str) else \"\"\n",
    "\n",
    "    # (col, row) Ï¢åÌëú Îß§Ìïë\n",
    "    if \"healthy\" in label_lower:\n",
    "        pos = (0, 0)  # ÌñâÎ≥µ üòä (Ï¢åÏÉÅ)\n",
    "    elif \"blight\" in label_lower or \"scorch\" in label_lower:\n",
    "        pos = (1, 0)  # Ïä¨Ìîî üò¢ (Ïö∞ÏÉÅ)\n",
    "    elif \"mildew\" in label_lower or \"virus\" in label_lower:\n",
    "        pos = (0, 1)  # ÏãúÎì¶/Ï°∏Î¶º üò¥ (Ï¢åÌïò)\n",
    "    else:\n",
    "        pos = (1, 1)  # ÌôúÏßù üòÑ (Ïö∞Ìïò)\n",
    "\n",
    "    # ‚úÖ 3. crop ÏòÅÏó≠ Í≥ÑÏÇ∞\n",
    "    x0 = pos[0] * cell_w\n",
    "    y0 = pos[1] * cell_h\n",
    "    img = sheet.crop((x0, y0, x0 + cell_w, y0 + cell_h))\n",
    "    img = img.resize((420, 420), Image.LANCZOS)\n",
    "    d = ImageDraw.Draw(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def avatar_png_bytes(state: Dict, full_label: str) -> bytes:\n",
    "    im = draw_plant_avatar(state, full_label)\n",
    "    buf = io.BytesIO()\n",
    "    im.convert(\"RGB\").save(buf, format=\"PNG\")\n",
    "    return buf.getvalue()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) ÏßàÎ≥ëÎ™Ö ‚Üí Í∞ÄÏù¥Îìú Î£∞Î∂Å (Î°úÏª¨)\n",
    "# =========================\n",
    "# Í≥µÌÜµ ÌÇ§: ÎÇÆÏùÄ ÏäµÎèÑ/Í≥ºÏäµ/ÌÜµÌíç/ÌñáÎπõ/Ïûé Í¥ÄÎ¶¨ Îì±Ïùò Î≥¥Ìé∏ Ï°∞Ïπò\n",
    "RULEBOOK: Dict[str, Dict[str, list[str] | tuple]] = {\n",
    "    # tomato\n",
    "    \"Early_blight\": {\n",
    "        \"actions\": [\"Í∞êÏóº Ïûé Ï†úÍ±∞\", \"Í¥ÄÏàòÎäî ÌÜ†Ïñë ÏúÑÏ£º(Ïûé Ï†ñÏßÄ ÏïäÍ≤å)\", \"ÌÜµÌíç Í∞ïÌôî\", \"ÌÜ†Ïñë Í≥ºÏäµ Í∏àÏßÄ\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 27), \"moisture\": (40, 60)},\n",
    "        \"note\": \"ÌïòÎ∂Ä ÏûéÎ∂ÄÌÑ∞ ÌçºÏßê, ÏûéÏóê ÎèôÏã¨Ïõê Î¨¥Îä¨Í∞Ä ÌäπÏßï\"\n",
    "    },\n",
    "    \"Late_blight\": {\n",
    "        \"actions\": [\"Í∞êÏóº Î∂ÄÏúÑ Ï¶âÏãú Ï†úÍ±∞\", \"Î∂ÑÎ¨¥ Ï§ëÎã®\", \"ÌÜµÌíç/ÏùÄÏùÄÌïú ÌñáÎπõ Ïú†ÏßÄ\", \"Í¥ÄÏàò ÌõÑ ÌëúÎ©¥ Í±¥Ï°∞\"],\n",
    "        \"target\": {\"humidity\": (40, 55), \"temperature\": (18, 24), \"moisture\": (40, 55)},\n",
    "        \"note\": \"Ïûé/Ï§ÑÍ∏∞/Ïó¥Îß§Ïóê Îπ†Î•¥Í≤å ÌôïÏÇ∞, Í≥ºÏäµ¬∑Ï†ÄÏò®ÏóêÏÑú Ïã¨Ìï¥Ïßê\"\n",
    "    },\n",
    "    \"Leaf_Mold\": {\n",
    "        \"actions\": [\"ÌÜµÌíç Í∞ïÌôî\", \"Ïûé Ï†ñÏßÄ ÏïäÍ≤å\", \"ÌïòÏö∞Ïä§ ÎÇ¥ ÏÉÅÎåÄÏäµÎèÑ ÎÇÆÏ∂îÍ∏∞\"],\n",
    "        \"target\": {\"humidity\": (40, 55), \"temperature\": (20, 26), \"moisture\": (40, 60)},\n",
    "        \"note\": \"Ïûé Îí∑Î©¥ Í≥∞Ìå°Ïù¥ÏÑ± Ìè¨ÏûêÏ∏µ\"\n",
    "    },\n",
    "    \"Bacterial_spot\": {\n",
    "        \"actions\": [\"Î¨ºÌäÄÍπÄ ÏµúÏÜåÌôî\", \"Í∞êÏóº Ïûé/Ïó¥Îß§ Ï†úÍ±∞\", \"ÎèÑÍµ¨ ÏÜåÎèÖ\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 27), \"moisture\": (40, 60)},\n",
    "        \"note\": \"ÏÑ∏Í∑†ÏÑ± Î∞òÏ†ê, Î¨ºÎ∞©Ïö∏ Ï†ÑÏóº Ï£ºÏùò\"\n",
    "    },\n",
    "    \"Septoria_leaf_spot\": {\n",
    "        \"actions\": [\"Í∞êÏóº Ïûé Ï†úÍ±∞\", \"ÌïòÎ∂Ä Ïûé Ï†ïÎ¶¨Î°ú ÌÜµÌíç ÌôïÎ≥¥\", \"ÌÜ†Ïñë ÏúÑÏ£º Í¥ÄÏàò\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 26), \"moisture\": (40, 60)},\n",
    "        \"note\": \"ÏûéÏóê ÏûëÏùÄ ÌöåÍ∞àÏÉâ Î∞òÏ†ê Îã§Ïàò\"\n",
    "    },\n",
    "    \"Target_Spot\": {\n",
    "        \"actions\": [\"ÏÉÅÏ≤òÎ∂ÄÏúÑ Ï†úÍ±∞\", \"Í¥ÄÏàòÎüâ Ï†àÏ†ú\", \"ÌÜµÌíç Í∞ïÌôî\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 27), \"moisture\": (40, 60)},\n",
    "        \"note\": \"Í≥ºÏäµ/Í≥†Ïò® Ï°∞Í±¥ÏóêÏÑú ÏïÖÌôî\"\n",
    "    },\n",
    "    \"Tomato_mosaic_virus\": {\n",
    "        \"actions\": [\"Ïò§Ïóº Í∞ÄÎä• ÎèÑÍµ¨/ÏÜê ÏÜåÎèÖ\", \"Í∞êÏóº ÏãùÎ¨º Í≤©Î¶¨/ÌèêÍ∏∞\", \"Ìï¥Ï∂© Î∞©Ï†ú Î≥ëÌñâ\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 26), \"moisture\": (40, 60)},\n",
    "        \"note\": \"Î∞îÏù¥Îü¨Ïä§ÏÑ±‚ÄîÌôîÌïôÏ†Å ÏπòÎ£å Î∂àÍ∞Ä, Ï†ÑÏóº Ï∞®Îã®Ïù¥ ÌïµÏã¨\"\n",
    "    },\n",
    "    \"Tomato_Yellow_Leaf_Curl_Virus\": {\n",
    "        \"actions\": [\"Í∞êÏóº Í∞úÏ≤¥ Í≤©Î¶¨\", \"ÏßÑÎîßÎ¨ºÎ•ò Îß§Í∞ú Ìï¥Ï∂© Ï∞®Îã®\", \"ÏúÑÏÉùÍ¥ÄÎ¶¨\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 28), \"moisture\": (40, 60)},\n",
    "        \"note\": \"Î∞îÏù¥Îü¨Ïä§ÏÑ±‚ÄîÌï¥Ï∂© Í¥ÄÎ¶¨ ÌïÑÏàò\"\n",
    "    },\n",
    "    \"Spider_mites Two-spotted_spider_mite\": {\n",
    "        \"actions\": [\"Ïûé Îí∑Î©¥ ÌôïÏù∏/Î¨ºÎ¶¨Ï†Å Ï†úÍ±∞\", \"ÏäµÎèÑ ÏïΩÍ∞Ñ ÏÉÅÌñ•\", \"ÌÜµÌíçÍ≥º Í¥ë Ïú†ÏßÄ\"],\n",
    "        \"target\": {\"humidity\": (50, 65), \"temperature\": (20, 26), \"moisture\": (45, 65)},\n",
    "        \"note\": \"ÏùëÏï†Î•ò‚ÄîÎØ∏ÏÑ∏Ìïú Ìù°Ï¶ô ÌîºÌï¥/Í±∞ÎØ∏Ï§Ñ\"\n",
    "    },\n",
    "    # pepper (bell)\n",
    "    \"Bacterial_spot_pepper\": {\n",
    "        \"actions\": [\"Î¨ºÌäÄÍπÄ ÏµúÏÜåÌôî\", \"Í∞êÏóº Ïûé/Ïó¥Îß§ Ï†úÍ±∞\", \"ÎèÑÍµ¨/ÏÜê ÏÜåÎèÖ\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 27), \"moisture\": (40, 60)},\n",
    "        \"note\": \"ÌååÌîÑÎ¶¨Ïπ¥ ÏÑ∏Í∑†ÏÑ± Î∞òÏ†ê\"\n",
    "    },\n",
    "    # strawberry\n",
    "    \"Leaf_scorch\": {\n",
    "        \"actions\": [\"Í≥ºÏäµ Ï£ºÏùò\", \"ÌÜµÌíç/ÌñáÎπõ ÌôïÎ≥¥\", \"Ïò§ÎûòÎêú Ïûé Ï†úÍ±∞\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (18, 24), \"moisture\": (45, 60)},\n",
    "        \"note\": \"Ïûé Í∞ÄÏû•ÏûêÎ¶¨ Í∞àÎ≥Ä\"\n",
    "    },\n",
    "    \"Powdery_mildew\": {\n",
    "        \"actions\": [\"Ïûé Ï†ñÏßÄ ÏïäÍ≤å\", \"ÏäµÎèÑ ÎÇÆÏ∂îÍ∏∞\", \"ÌÜµÌíç Í∞ïÌôî\"],\n",
    "        \"target\": {\"humidity\": (40, 55), \"temperature\": (20, 26), \"moisture\": (40, 60)},\n",
    "        \"note\": \"Ìù∞Í∞ÄÎ£®\"\n",
    "    },\n",
    "    \"healthy\": {\n",
    "        \"actions\": [\"Î£®Ìã¥ Ïú†ÏßÄ\", \"ÏùÄÏùÄÌïú ÌñáÎπõ\", \"Ï†ÅÏ†ï Í¥ÄÏàò\", \"Í∞ÄÎ≤ºÏö¥ ÎπÑÎ£å\"],\n",
    "        \"target\": {\"humidity\": (45, 65), \"temperature\": (20, 28), \"moisture\": (45, 70)},\n",
    "        \"note\": \"Ï†ïÏÉÅ\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ÏßàÎ≥ëÎ™Ö Ï†ïÍ∑úÌôî: PlantVillage Ìè¥ÎçîÎ™ÖÏùÑ Î£∞Î∂Å ÌÇ§Î°ú Îß§Ìïë\n",
    "def normalize_key(crop: str, disease: str) -> str:\n",
    "    d = (disease or \"\").strip()\n",
    "    if \"healthy\" in d.lower(): return \"healthy\"\n",
    "    # pepper Ï†ÑÏö© ÌÇ§\n",
    "    if crop.startswith(\"Pepper\") and \"bacterial_spot\" in d.lower():\n",
    "        return \"Bacterial_spot_pepper\"\n",
    "    # Í∑∏ÎåÄÎ°ú Ï°¥Ïû¨ÌïòÎ©¥ Í∑∏ÎåÄÎ°ú\n",
    "    if d in RULEBOOK: return d\n",
    "    # ÏïΩÌïú Ï†ïÍ∑úÌôî\n",
    "    d2 = d.replace(\" \", \"_\")\n",
    "    if d2 in RULEBOOK: return d2\n",
    "    return d  # ÎØ∏Ï†ïÏùòÎ©¥ Í∑∏ÎåÄÎ°ú Î∞òÌôò(LLM Î≥¥Í∞ïÏù¥ÎÇò Í∏∞Î≥∏ Í≥µÌÜµ Í∞ÄÏù¥Îìú ÏÇ¨Ïö©)\n",
    "\n",
    "def build_local_guide(crop: str, disease: str) -> Dict:\n",
    "    \"\"\"\n",
    "    YOLO ÏòàÏ∏°Îêú ÏûëÎ¨º¬∑ÏßàÎ≥ëÎ™Ö Í∏∞Î∞òÏúºÎ°ú\n",
    "    ÏãùÎ¨ºÏù¥ ÏßÅÏ†ë ÎßêÌïòÎäî ÎìØÌïú ÌïúÍ∏Ä Î©òÌä∏ÏôÄ ÏπòÎ£å Í∞ÄÏù¥ÎìúÎ•º Î∞òÌôò.\n",
    "    \"\"\"\n",
    "\n",
    "    # ‚úÖ ÏòÅÏñ¥ ÎùºÎ≤® ‚Üí ÌïúÍ∏Ä Îß§Ìïë\n",
    "    CROP_KR = {\n",
    "        \"Tomato\": \"ÌÜ†ÎßàÌÜ†\",\n",
    "        \"Pepper,_bell\": \"ÌååÌîÑÎ¶¨Ïπ¥\",\n",
    "        \"Strawberry\": \"Îî∏Í∏∞\",\n",
    "    }\n",
    "\n",
    "    DISEASE_KR = {\n",
    "        \"healthy\": \"Í±¥Í∞ïÌï¥Ïöî\",\n",
    "        \"Bacterial_spot\": \"ÏÑ∏Í∑†ÏÑ± Ï†êÎ¨¥Îä¨Î≥ë\",\n",
    "        \"Early_blight\": \"ÏûéÎßàÎ¶ÑÎ≥ë\",\n",
    "        \"Late_blight\": \"ÏûøÎπõÍ≥∞Ìå°Ïù¥Î≥ë\",\n",
    "        \"Leaf_Mold\": \"ÏûéÍ≥∞Ìå°Ïù¥Î≥ë\",\n",
    "        \"Septoria_leaf_spot\": \"Ï†êÎ¨¥Îä¨Î≥ë\",\n",
    "        \"Spider_mites Two-spotted_spider_mite\": \"Ï†êÎ∞ïÏù¥ÏùëÏï† ÌîºÌï¥\",\n",
    "        \"Target_Spot\": \"Í∞àÏÉâÎ¨¥Îä¨Î≥ë\",\n",
    "        \"Tomato_mosaic_virus\": \"ÌÜ†ÎßàÌÜ†Î™®ÏûêÏù¥ÌÅ¨Î∞îÏù¥Îü¨Ïä§\",\n",
    "        \"Tomato_Yellow_Leaf_Curl_Virus\": \"Ìô©ÌôîÏûéÎßêÎ¶ºÎ∞îÏù¥Îü¨Ïä§\",\n",
    "        \"Leaf_scorch\": \"ÏûéÎßàÎ¶ÑÏ¶ù\",\n",
    "    }\n",
    "\n",
    "    crop_kr = CROP_KR.get(crop, crop)\n",
    "    disease_kr = DISEASE_KR.get(disease, disease.replace(\"_\", \" \"))\n",
    "\n",
    "    key = normalize_key(crop, disease)\n",
    "    node = RULEBOOK.get(key)\n",
    "\n",
    "    # üü¢ Í±¥Í∞ïÌïú Í≤ΩÏö∞\n",
    "    if key == \"healthy\":\n",
    "        return {\n",
    "            \"title\": f\"{crop_kr} ¬∑ Í±¥Í∞ï\",\n",
    "            \"tip\": f\"üòä Ï†ÄÎäî {crop_kr}ÏòàÏöî! ÏßÄÍ∏à ÏïÑÏ£º Í±¥Í∞ïÌï¥Ïöî üåø\\n\"\n",
    "                   f\"ÌñáÎπõÎèÑ Ï¢ãÍ≥†, Î¨ºÎèÑ Ïûò ÎßûÏïÑÏöî ‚òÄÔ∏èüíß\\n\"\n",
    "                   f\"Ïò§ÎäòÎèÑ ÌñâÎ≥µÌïòÍ≤å Í¥ëÌï©ÏÑ± Ï§ëÏù¥ÏóêÏöî ‚ú®\",\n",
    "            \"actions\": node[\"actions\"] if node else [\"Î£®Ìã¥ Ïú†ÏßÄ\", \"Ï†ÅÏ†ï Í¥ÄÏàò\", \"ÌñáÎπõ Ïú†ÏßÄ\"],\n",
    "            \"target\": node[\"target\"] if node else {\"humidity\": (45, 65), \"temperature\": (20, 28), \"moisture\": (45, 70)},\n",
    "            \"danger\": None\n",
    "        }\n",
    "\n",
    "    # üî¥ Î≥ëÏù¥ ÏûàÎäî Í≤ΩÏö∞\n",
    "    if node:\n",
    "        return {\n",
    "            \"title\": f\"{crop_kr} ¬∑ {disease_kr}\",\n",
    "            \"tip\": f\"üò¢ Ï†ÄÎäî {crop_kr}Ïù∏Îç∞, ÏßÄÍ∏à **{disease_kr}**ÏùÑ(Î•º) ÏïìÍ≥† ÏûàÏñ¥Ïöî.\\n\"\n",
    "                   f\"ÎèÑÏôÄÏ£ºÏÑ∏Ïöî‚Ä¶ ÏïÑÎûòÏùò ÏπòÎ£åÍ∞Ä ÌïÑÏöîÌï¥Ïöî ü©∫\",\n",
    "            \"actions\": node[\"actions\"],\n",
    "            \"target\": node[\"target\"],\n",
    "            \"danger\": \"‚ö†Ô∏è Í≥ºÏäµ¬∑Î∞ÄÌèê¬∑Ïûé Ï†ñÏùåÏùÄ ÎåÄÎ∂ÄÎ∂ÑÏùò Î≥ëÏùÑ ÏïÖÌôîÏãúÏºúÏöî. Ï£ºÏùòÌï¥Ï£ºÏÑ∏Ïöî!\"\n",
    "        }\n",
    "\n",
    "    # ‚ö™ ÎØ∏Ï†ïÏùò ÏßàÎ≥ë (Î£∞Î∂ÅÏóê ÏóÜÏùå)\n",
    "    return {\n",
    "        \"title\": f\"{crop_kr} ¬∑ {disease_kr}\",\n",
    "        \"tip\": f\"ü§î Ï†ÄÎäî {crop_kr}Ïù∏Îç∞, **{disease_kr}**(Ïù¥)ÎùºÎäî ÏÉÅÌÉúÏù∏ Í≤É Í∞ôÏïÑÏöî.\\n\"\n",
    "               f\"Ï†ïÌôïÌïú Î≥ëÎ™ÖÏùÄ Ïûò Î™®Î•¥Í≤†ÏßÄÎßå, ÏïÑÎûòÏùò Í∏∞Î≥∏ ÏπòÎ£åÎ•º Ìï¥Î≥¥ÏÑ∏Ïöî üå±\",\n",
    "        \"actions\": [\"ÌÜµÌíç Í∞ïÌôî\", \"Ïûé Ï†ñÏßÄ ÏïäÍ≤å\", \"Í¥ÄÏàòÎäî ÌÜ†Ïñë ÏúÑÏ£ºÎ°ú\", \"Í∞êÏóº ÏùòÏã¨ Ïûé Ï†úÍ±∞\"],\n",
    "        \"target\": {\"humidity\": (45, 60), \"temperature\": (20, 27), \"moisture\": (40, 60)},\n",
    "        \"danger\": \"‚ö†Ô∏è Í≥ºÏäµ¬∑Î∞ÄÌèê¬∑Î¨ºÌäÄÍπÄÏùÄ ÏïÖÌôî ÏöîÏù∏Ïù¥ÏóêÏöî. Ï°∞Ïã¨Ìï¥Ï£ºÏÑ∏Ïöî!\"\n",
    "    }\n",
    "\n",
    "    \n",
    "def llm_refine(guide: Dict, crop: str, disease: str, state: Dict, api_key_ok: bool) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    LLMÏù¥ ÏûëÎ¨º¬∑ÏßàÎ≥ë¬∑ÏÉÅÌÉú Í∏∞Î∞òÏúºÎ°ú Ïò§ÎäòÏùò Íµ¨Ï≤¥Ï†Å Ïï°ÏÖòÏùÑ Ï†úÏïà (Îã§ÎßàÍ≥†Ïπò ÎßêÌà¨)\n",
    "    \"\"\"\n",
    "    if not api_key_ok or ChatOpenAI is None:\n",
    "        return None\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)\n",
    "        prompt = (\n",
    "            \"ÎÑàÎäî Î∞òÎ†§ÏãùÎ¨º Îã§ÎßàÍ≥†ÏπòÏùò ÏãùÎ¨º ÏºÄÏñ¥ ÏΩîÏπòÏïº üå±\\n\"\n",
    "            \"ÏïÑÎûòÏùò Ï†ïÎ≥¥Î•º Î≥¥Í≥† ÏãùÎ¨ºÏóêÍ≤å Ïò§Îäò Ìï¥Ï§òÏïº Ìï† Íµ¨Ï≤¥Ï†ÅÏù∏ ÌñâÎèôÏùÑ 2~4Ï§ÑÎ°ú ÎßêÌï¥Ï§ò.\\n\"\n",
    "            \"ÎßêÌà¨Îäî Îã§Ï†ïÌïòÏßÄÎßå Í∞ÑÍ≤∞ÌïòÍ≤å, 'Î¨º Ï£ºÏÑ∏Ïöî üíß', 'ÏûéÏùÑ Îã¶ÏïÑÏ£ºÏÑ∏Ïöî üçÉ'Ï≤òÎüº Ïã§Ï†ú ÌñâÎèôÏùÑ Ï†úÏãúÌï¥.\\n\"\n",
    "            \"Í≥ºÌïôÏ†ÅÏúºÎ°ú ÏïàÏ†ÑÌïú Ï°∞ÏπòÎßå ÎßêÌï¥Ïïº Ìï¥. ÏúÑÌóòÌïòÍ±∞ÎÇò ÎèÖÏÑ± ÏûàÎäî ÌñâÎèôÏùÄ Ï†àÎåÄ Í∏àÏßÄ.\\n\\n\"\n",
    "            f\"ÏûëÎ¨ºÎ™Ö: {crop}\\n\"\n",
    "            f\"ÏòàÏ∏°Îêú ÏßàÎ≥ë: {disease}\\n\"\n",
    "            f\"ÌòÑÏû¨ ÏÉÅÌÉú ‚Üí ÏàòÎ∂Ñ {int(state['moisture'])}%, ÏäµÎèÑ {int(state['humidity'])}%, \"\n",
    "            f\"Ïò®ÎèÑ {state['temperature']:.1f}¬∞C, ÌñâÎ≥µÎèÑ {int(state['happiness'])}%\\n\"\n",
    "            f\"Í∂åÏû• Î≤îÏúÑ ‚Üí ÏäµÎèÑ {guide['target']['humidity'][0]}~{guide['target']['humidity'][1]}%, \"\n",
    "            f\"Ïò®ÎèÑ {guide['target']['temperature'][0]}~{guide['target']['temperature'][1]}¬∞C, \"\n",
    "            f\"ÏàòÎ∂Ñ {guide['target']['moisture'][0]}~{guide['target']['moisture'][1]}%\\n\"\n",
    "            f\"Ï∂îÏ≤ú ÌñâÎèô: {', '.join(guide['actions'])}\\n\"\n",
    "        )\n",
    "        resp = llm.invoke(prompt)\n",
    "        return resp.content if hasattr(resp, \"content\") else str(resp)\n",
    "    except Exception as e:\n",
    "        st.warning(f\"LLM Î≥¥Í∞ï Ï§ë Ïò§Î•ò: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Streamlit UI\n",
    "# =========================\n",
    "st.set_page_config(page_title=\"Î∞òÎ†§ÏãùÎ¨º ÎßàÏùåÏù¥ ‚ù§Ô∏è‚Äçü©π\", page_icon=\"üå±\", layout=\"centered\")\n",
    "st.title(\"‚ù§Ô∏è‚Äçü©π Î∞òÎ†§ÏãùÎ¨º ÏÑ±Ïû•ÏùºÍ∏∞ ÏÑúÎπÑÏä§ 'ÎßàÏùåÏù¥'\")\n",
    "\n",
    "# ÏÇ¨Ïù¥ÎìúÎ∞î\n",
    "st.sidebar.header(\"ÏÑ§Ï†ï\")\n",
    "weights_path = st.sidebar.text_input(\"YOLO Í∞ÄÏ§ëÏπò Í≤ΩÎ°ú\", str(DEFAULT_WEIGHTS))\n",
    "weights_path = Path(weights_path).resolve()\n",
    "use_llm = st.sidebar.toggle(\"AI ÏßÄÏãù Î≤†ÌÉÄ(LLM Î≥¥Í∞ï) ÏÇ¨Ïö©\", value=False,\n",
    "                            help=\"ÎùºÎ≤®Í≥º ÌòÑÏû¨ ÏÉÅÌÉúÎ•º Î∞îÌÉïÏúºÎ°ú LLMÏù¥ Ìïú Î≤à Îçî ÏöîÏïΩ Í∞ÄÏù¥ÎìúÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.\")\n",
    "api_key_ok = (ChatOpenAI is not None)\n",
    "\n",
    "if use_llm and not api_key_ok:\n",
    "    st.sidebar.warning(\"langchain_openai ÎØ∏ÏÑ§Ïπò ÎòêÎäî ÌôòÍ≤ΩÌÇ§ ÎØ∏ÏÑ§Ï†ï. Î°úÏª¨ Î£∞Î∂ÅÎßå ÏÇ¨Ïö©Ìï©ÎãàÎã§.\")\n",
    "\n",
    "model = load_yolo(weights_path)\n",
    "\n",
    "# ÏÉÅÌÉú Î°úÎî© & ÏûêÏó∞Í∞êÏÜå\n",
    "if \"state\" not in st.session_state:\n",
    "    st.session_state.state = load_state()\n",
    "st.session_state.state = decay_state(st.session_state.state)\n",
    "# ÎàÑÎùΩ ÌÇ§ Î≥¥ÏôÑ\n",
    "for k, v in DEFAULT_STATE.items():\n",
    "    if k not in st.session_state.state:\n",
    "        st.session_state.state[k] = v\n",
    "# üëá Ï∂îÍ∞Ä\n",
    "if \"born_at\" not in st.session_state.state:\n",
    "    st.session_state.state[\"born_at\"] = time.time()\n",
    "\n",
    "name = st.text_input(\"Î∞òÎ†§ÏãùÎ¨º Ïù¥Î¶Ñ\", st.session_state.state.get(\"name\", \"ÎÇòÏùò Î∞òÎ†§ÏãùÎ¨º\"))\n",
    "st.session_state.state[\"name\"] = name\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ ÏûÖÎ†•\n",
    "st.subheader(\"üì∏ ÏÇ¨ÏßÑÏúºÎ°ú ÏÉÅÌÉú ÏßÑÎã®\")\n",
    "col1, col2 = st.columns(2)\n",
    "with col1:\n",
    "    img_file = st.file_uploader(\"Ïù¥ÎØ∏ÏßÄ ÏóÖÎ°úÎìú\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "with col2:\n",
    "    cam = st.camera_input(\"Ïπ¥Î©îÎùº Ï¥¨ÏòÅ(ÏÑ†ÌÉù)\")\n",
    "\n",
    "image = None\n",
    "img_source = None\n",
    "if cam is not None:\n",
    "    from PIL import Image as PILImage, ImageFont\n",
    "    image = PILImage.open(cam)\n",
    "    img_source = \"camera\"\n",
    "elif img_file is not None:\n",
    "    from PIL import Image as PILImage, ImageFont\n",
    "    image = PILImage.open(img_file)\n",
    "    img_source = \"upload\"\n",
    "\n",
    "if image:\n",
    "    st.image(image, caption=\"ÏûÖÎ†• Ïù¥ÎØ∏ÏßÄ\", use_container_width=True)\n",
    "    tmp_path = Path(\"./_tmp_input.jpg\").resolve()\n",
    "    image.convert(\"RGB\").save(tmp_path)\n",
    "    label, conf, crop, disease = yolo_predict_multiclass(model, tmp_path)\n",
    "    st.session_state.state.update({\n",
    "        \"last_label\": label,\n",
    "        \"last_conf\": conf,\n",
    "        \"last_crop\": crop,\n",
    "        \"last_disease\": disease\n",
    "    })\n",
    "else:\n",
    "    label = st.session_state.state.get(\"last_label\")\n",
    "    conf = st.session_state.state.get(\"last_conf\")\n",
    "    crop = st.session_state.state.get(\"last_crop\") or \"unknown\"\n",
    "    disease = st.session_state.state.get(\"last_disease\") or \"unknown\"\n",
    "\n",
    "# ÏïÑÎ∞îÌÉÄ\n",
    "import base64\n",
    "\n",
    "current_label = st.session_state.state.get(\"last_label\") or \"unknown\"\n",
    "avatar_bytes = avatar_png_bytes(st.session_state.state, current_label)\n",
    "\n",
    "# base64 Ïù∏ÏΩîÎî©\n",
    "encoded = base64.b64encode(avatar_bytes).decode()\n",
    "\n",
    "# HTML Ï§ëÏïô Ï†ïÎ†¨\n",
    "st.markdown(\n",
    "    f\"\"\"\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"data:image/png;base64,{encoded}\" width=\"420\" style=\"margin:auto;\" />\n",
    "        <p style=\"font-size: 16px; color: #ccc;\">{name}Ïùò ÌòÑÏû¨ Í∏∞Î∂Ñ</p>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")\n",
    "\n",
    "\n",
    "# Í≤∞Í≥º ÌëúÏãú\n",
    "if st.session_state.state.get(\"last_label\"):\n",
    "    st.success(f\"ÏßÑÎã®: **{st.session_state.state['last_label']}** (Ïã†Î¢∞ÎèÑ {st.session_state.state['last_conf']:.2f})\")\n",
    "    st.caption(\n",
    "        f\"ÏûëÎ¨º: **{st.session_state.state.get('last_crop', 'unknown')}**, \"\n",
    "        f\"ÏßàÎ≥ë: **{st.session_state.state.get('last_disease', 'unknown')}**, \"\n",
    "        f\"ÏÜåÏä§: {img_source or '-'}\"\n",
    "    )\n",
    "else:\n",
    "    st.info(\"ÏÇ¨ÏßÑÏùÑ ÏóÖÎ°úÎìúÌï¥ ÏßÑÎã®ÏùÑ Î∞õÏïÑÎ≥¥ÏÑ∏Ïöî.\")\n",
    "\n",
    "# Í∞ÄÏù¥Îìú ÏÉùÏÑ±\n",
    "if st.session_state.state.get(\"last_disease\"):\n",
    "    guide = build_local_guide(st.session_state.state[\"last_crop\"], st.session_state.state[\"last_disease\"])\n",
    "    st.subheader(\"ü©∫ ÏºÄÏñ¥ Í∞ÄÏù¥Îìú\")\n",
    "    st.info(guide[\"tip\"])\n",
    "    if \"danger\" in guide and guide[\"danger\"]:\n",
    "        st.warning(guide[\"danger\"])\n",
    "    st.write(\"**Ï∂îÏ≤ú ÌñâÎèô:** \" + \" ¬∑ \".join(guide[\"actions\"]))\n",
    "    st.caption(f\"Í∂åÏû• Î≤îÏúÑ ‚Üí ÏäµÎèÑ {guide['target']['humidity'][0]} ~ {guide['target']['humidity'][1]}% ¬∑ \"\n",
    "               f\"Ïò®ÎèÑ {guide['target']['temperature'][0]} ~ {guide['target']['temperature'][1]}¬∞C ¬∑ \"\n",
    "               f\"ÏàòÎ∂Ñ {guide['target']['moisture'][0]} ~ {guide['target']['moisture'][1]}%\")\n",
    "\n",
    "    # üí¨ LLM Î≥¥Í∞ï(ÏòµÏÖò)\n",
    "    if use_llm and api_key_ok:\n",
    "        with st.spinner(\"AIÍ∞Ä ÎßûÏ∂§ ÏºÄÏñ¥ Î¨∏Ïû•ÏùÑ Ï§ÄÎπÑ Ï§ë...\"):\n",
    "            msg = llm_refine(\n",
    "                guide,\n",
    "                st.session_state.state[\"last_crop\"],\n",
    "                st.session_state.state[\"last_disease\"],\n",
    "                st.session_state.state,\n",
    "                api_key_ok\n",
    "            )\n",
    "        if msg:\n",
    "            st.markdown(\"### üåº AI ÎßûÏ∂§ Ï°∞Ïñ∏\")\n",
    "            st.success(msg)\n",
    "\n",
    "\n",
    "# ÏÉÅÌÉú Í≤åÏù¥ÏßÄ\n",
    "st.subheader(\"üß™ ÏÉÅÌÉú\")\n",
    "a, b = st.columns(2)\n",
    "with a:\n",
    "    st.progress(int(st.session_state.state[\"moisture\"]), text=f\"ÌÜ†Ïñë ÏàòÎ∂Ñ: {int(st.session_state.state['moisture'])}%\")\n",
    "    st.progress(int(st.session_state.state[\"humidity\"]), text=f\"ÎåÄÍ∏∞ ÏäµÎèÑ: {int(st.session_state.state['humidity'])}%\")\n",
    "    st.progress(int(st.session_state.state[\"nutrients\"]), text=f\"ÏòÅÏñë: {int(st.session_state.state['nutrients'])}%\")\n",
    "with b:\n",
    "    st.progress(int(st.session_state.state[\"happiness\"]), text=f\"ÌñâÎ≥µ: {int(st.session_state.state['happiness'])}%\")\n",
    "    st.metric(\"Ïò®ÎèÑ\", f\"{st.session_state.state['temperature']:.1f} ¬∞C\")\n",
    "\n",
    "# ÌñâÎèô Î≤ÑÌäº\n",
    "st.subheader(\"üéÆ ÌñâÎèô\")\n",
    "c1, c2, c3, c4, c5 = st.columns(5)\n",
    "if c1.button(\"üíß Î¨ºÏ£ºÍ∏∞\"):\n",
    "    st.session_state.state[\"moisture\"] = clamp(st.session_state.state[\"moisture\"] + 12, 0, 100)\n",
    "    st.session_state.state[\"happiness\"] = clamp(st.session_state.state[\"happiness\"] + 3, 0, 100)\n",
    "\n",
    "if c2.button(\"üå´Ô∏è Î∂ÑÎ¨¥\"):\n",
    "    st.session_state.state[\"humidity\"] = clamp(st.session_state.state[\"humidity\"] + 8, 0, 100)\n",
    "    st.session_state.state[\"happiness\"] = clamp(st.session_state.state[\"happiness\"] + 2, 0, 100)\n",
    "\n",
    "if c3.button(\"‚òÄÔ∏è ÌñáÎπõ/ÌÜµÌíç\"):\n",
    "    st.session_state.state[\"temperature\"] = clamp(st.session_state.state[\"temperature\"] + 0.8, 10, 40)\n",
    "    st.session_state.state[\"happiness\"] = clamp(st.session_state.state[\"happiness\"] + 2, 0, 100)\n",
    "    st.session_state.state[\"humidity\"] = clamp(st.session_state.state[\"humidity\"] - 2, 0, 100)\n",
    "\n",
    "if c4.button(\"üß™ ÎπÑÎ£å\"):\n",
    "    st.session_state.state[\"nutrients\"] = clamp(st.session_state.state[\"nutrients\"] + 10, 0, 100)\n",
    "    st.session_state.state[\"happiness\"] = clamp(st.session_state.state[\"happiness\"] + 2, 0, 100)\n",
    "\n",
    "if c5.button(\"üßπ Ïûé Ï†ïÎ¶¨\"):\n",
    "    st.session_state.state[\"happiness\"] = clamp(st.session_state.state[\"happiness\"] + 3, 0, 100)\n",
    "\n",
    "save_state(st.session_state.state)\n",
    "\n",
    "st.caption(\"‚Äª Ïù¥ Ïï±ÏùÄ ÌïôÏäµÎêú Îã§Ï§ë ÌÅ¥ÎûòÏä§ ÎùºÎ≤®(Ïòà: Tomato___Early_blight)ÏùÑ ÏÇ¨Ïö©Ìï¥ ÏûëÎ¨º¬∑ÏßàÎ≥ëÎ™Ö Í∏∞Î∞ò Í∞ÄÏù¥ÎìúÎ•º Ï†úÏãúÌï©ÎãàÎã§. \"\n",
    "           \"LLM Î≥¥Í∞ï Î™®ÎìúÎäî Í∞úÏù∏ÌôîÎêú ÎßêÌà¨/ÏöîÏïΩÏùÑ Ï∂îÍ∞ÄÎ°ú Ï†úÍ≥µÌï©ÎãàÎã§(Ï†ÑÎ¨∏ ÏßÑÎã® ÎåÄÏ≤¥ ÏïÑÎãò).\") # Ï∂îÌõÑ Î≥ÄÍ≤Ω "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2ecfdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TCP    0.0.0.0:8501           0.0.0.0:0              LISTENING       10364\n",
      "  TCP    [::]:8501              [::]:0                 LISTENING       10364\n",
      "  TCP    [::1]:8501             [::1]:63054            ESTABLISHED     10364\n",
      "  TCP    [::1]:8501             [::1]:63055            ESTABLISHED     10364\n",
      "  TCP    [::1]:63054            [::1]:8501             ESTABLISHED     17192\n",
      "  TCP    [::1]:63055            [::1]:8501             ESTABLISHED     17192\n"
     ]
    }
   ],
   "source": [
    "!netstat -ano | findstr :8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de57d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÔøΩÔøΩÔøΩÔøΩ: ÔøΩÔøΩÔøΩŒºÔøΩÔøΩÔøΩ(PID 17192)ÔøΩÔøΩ ÔøΩÔøΩÔøΩÔøΩ«æÔøΩÔøΩÔøΩÔøΩœ¥ÔøΩ.\n"
     ]
    }
   ],
   "source": [
    "!taskkill /PID 17192 /F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0c92768-d747-4588-932f-d48749918718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://172.30.1.83:8501\n",
      "  External URL: http://118.37.88.101:8501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ïã§ÌñâÎêú ÎßÅÌÅ¨Î•º ÎàÑÎ•¥Î©¥ ÏÑúÎπÑÏä§ ÌôîÎ©¥ÏúºÎ°ú Ï†ëÏÜçÎê©ÎãàÎã§ !\n",
    "\n",
    "!streamlit run plant_pet_app.py --server.headless true --server.port 8501"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
